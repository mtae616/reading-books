# 데이터
- 세가지 비밀
    - 인덱스가 도움이 되지 않을 수 있다.
      - 인덱스가 무한한 데이터 크기에 대해 무한한 영향력을 제공하지 않는다는 의미
      - 인덱스 스캔
        - 인덱스 스캔은 테이블이 커질수록 인덱스고 함께 커지므로 (더 많은 테이블 행, 더 많은 인덱스값) 영향력이 점점 감소
        - 인덱스 스캔은 테이블의 행 수가 증가할수록 인덱스 스캔을 사용하는 쿼리에 대한 응답 시간도 늘어나므로 반드시 지연 시간이 발생
      - 행 찾기
        - 쿼리가 너무 많은 행을 검사
        - `만약 인덱스 조회 접근 유형이 아래와 같지 않다면 주의를 기울여야 함`
          - system
          - const
          - eq_ref
          - unique_subquery
      - 테이블 조인
        - NLJ, 테이블당 100개의 행만 있는 3개 테이블 조인은 100만개의 행에 접근
      - 작업 세트 크기
        - 쿼리가 조회하는 인덱스값이 메모리에 없으면 MySQL 은 디스크에서 값을 읽음
        - 또한 인덱스끼리 메모리를 놓고 경쟁 => 스토리지 입출력 증가
        - 인덱스값과 이들이 참조하는 프라이머리 키 행을 작업 세트라고 하며 보통 전체 데이터 크기의 10% 에 해당하는 메모리 할당
    - 데이터가 적을수록 좋다
      - 100 GB 가 100 TB 보다 나음...
    - QPS 가 낮을 수록 좋다
      - QPS 는 숫자에 불과하며 원시 처리량을 측정한 값이다
      - QPS 값은 애플리케이션과 관련해서만 의미가 있다.
- 최소 데이터 원칙
  - 필요한 데이터만 저장과 접근
  - 데이터 접근
    - `효율적인 데이터 접근을 위한 조건`
      - 필요한 열만 반환
        - `SELECT *` 을 하지마라
        - 특히 BLOB, TEXT, JSON 열이 있을 때는 더욱 더
      - 쿼리 복잡성 감소
      - 행 접근 제한
        - 범위와 목록을 제한할 것
        - `LIMIT` 은 행을 일치시킨 후 결과 세트에 적용되므로 행 접근을 제한하지 않는다.
        - `ORDER BY ... LIMIT` 최적화는 예외, 인덱스를 사용하여 정렬을 수행하고 결과 세트를 제한
      - 결과 세트 제한
        - 될 수 있는 한 적은 수의 행을 반환
        - where 조건 확인
        - `limit` 대신 `order by ... limit + limit offset` 사용
        - 행수를 계산하지 말고, 쿼리에서 `count(*)` 사용할 것
          - `select count(*) from talbe (where 절 없음)` 프라이머리 키를 병렬로 읽기 위해 다중 스레드를 사용
            - `parallel clustered index reads` 라고 부름
      - 행 정렬 피하기 => 일반적으로 성능에 영향을 미치지는 않음
        - 만약 limit 절이 없다면 order by 는 삭제할 수 있음
        - order by 절이 있지만 limit 절이 없는 쿼리를 찾은 다음 애플리케이션에서 정렬할 수 있는지 확인할 것
- 데이터 스토리지
  - `효율적인 데이터 스토리지 조건`
    - 필요한 행만 저장됨
    - 모든 열이 사용됨
    - 모든 열이 간결하고 실용적임
      - 고전적인 안티패턴은 `VARCHAR(255)` 를 사용하는 것 : VARCHAR 는 가변길이이므로 잘 확인하고 쓸것
      - BLOB(s3가 더 나음...), TEXT, JSON 은 특히 주의
    - 모든 값이 간결하고 실용적임
      - 공백 등, 데이터 타입 (yml 같은거...) 에 필용하지 않다면 최소화할것
      - UUID 는 BINARY(N) 으로 저장할 것 -> UUID_TO_BIN(), BIN_TO_UUID() 사용
      - 중복값 제거를 위해 데이터베이스 정규화를 유지할것 (id 를 int 값으로 받을 수 있어서 실용적)
    - 모든 세컨더리 인덱스가 사용되며 중복되지 않음
    - 필요한 행만 유지됨
- 데이터 삭제 또는 보관
  - 데이터가 너무 많아 성능 이슈가 발생할 때
  - 도구
    - sql 문을 실행하는 반복문을 작성(...?)
    - 각주 : 배치처럼 하라는 뜻인듯
  - 배치 크기
    - 행이 작고 큰 부하가 없을 때 단일 delete 는 1000 개 이하의 행을 수동 삭제하는 것이 안전
      - 수동 : 직렬(하나씩)로 실행
      - delete 문을 실행하는 데 500ms 를 넘지 않아야 함
        - 다음과 같은 이유
        - 복제 지연
          - delete 문을 실행하는 데 500ms 가 걸렸다면 복제본에서 실행하는 데 500ms 가 더 걸림 (replication 1대면, master 500ms + replica 500ms)
        - 스로틀링
          - 스로틀링이 없으면 대량 쓰기가 다른 쿼리를 방해하고 애플리케이션에 영향을 줄 수 있음
  - 로우 락 경합
    - 애플리케이션이 갱신하는 행과 delete 하는 행이 같을 때 락 경합 발생
  - 공간과 시간
    - fragmentation -> alter table, optimize table, pt-osc
  - 바이너리 로그 역설
    - 데이터를 삭제하면 binlog 에 기록됨, BLOB, TEXT, JSON 이 포함된 경우 binlog 급격히 늘어날 수 있음
      - `binlog_row_image`
        - `full` : 모든 열을 기록
        - `minimal` : 변경된 열만 기록
        - `noblob` : BLOB, TEXT, JSON 을 제외한 모든 열을 기록
        - 바이너리 로그의 전체 행 이미지에 의존하는 외부 서비스가 없는 경우 minimal 또는 noblob을 사용하는 것이 권장됨 